{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalan Lecture Processor\n",
    "\n",
    "Upload a university lecture recorded in Catalan and get:\n",
    "- **Full transcription** (using Whisper fine-tuned for Catalan)\n",
    "- **Cleaned text** (filler words removed, restructured into paragraphs)\n",
    "- **Translations** (Spanish, English, Portuguese, Italian)\n",
    "- **Summary** with key concepts\n",
    "- **PowerPoint slides**\n",
    "\n",
    "## Instructions\n",
    "1. **Runtime > Change runtime type > T4 GPU** (important!)\n",
    "2. **Runtime > Run all** (or click each cell in order)\n",
    "3. Wait ~2-3 minutes for models to download\n",
    "4. A **public link** will appear at the bottom - open it on your phone or computer\n",
    "5. Upload your audio file, select languages, click **Process Lecture**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 1: Check GPU\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected! Go to Runtime > Change runtime type > T4 GPU\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 2: Install dependencies\n%%capture\n!pip install -q transformers accelerate gradio python-pptx\n!pip install -q google-genai huggingface-hub faster-whisper\n!pip install -q sentencepiece protobuf pydub tqdm\n!apt-get -qq install -y ffmpeg\nprint(\"Dependencies installed!\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 3: Optional - Set Gemini API key for better text cleanup & summarization\n",
    "# Get a FREE key at https://ai.google.dev/\n",
    "# Leave empty to skip (system will still work, just without LLM cleanup)\n",
    "\n",
    "import os\n",
    "GEMINI_API_KEY = \"\"  # @param {type:\"string\"}\n",
    "if GEMINI_API_KEY:\n",
    "    os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
    "    print(\"Gemini API key set!\")\n",
    "else:\n",
    "    print(\"No Gemini key - text cleanup will use regex only (still works fine)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 4: Core configuration\n",
    "\n",
    "import re\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import logging\n",
    "import tempfile\n",
    "from datetime import date\n",
    "\n",
    "import requests\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\")\n",
    "logger = logging.getLogger(\"lecture_processor\")\n",
    "\n",
    "# ── Configuration ──────────────────────────────────────────────────────────────\n",
    "\n",
    "WHISPER_HF_MODEL = \"projecte-aina/whisper-large-v3-ca-3catparla\"\n",
    "NLLB_MODEL = \"facebook/nllb-200-distilled-600M\"\n",
    "\n",
    "LANGUAGE_CODES = {\n",
    "    \"Catalan\": \"cat_Latn\",\n",
    "    \"Spanish\": \"spa_Latn\",\n",
    "    \"English\": \"eng_Latn\",\n",
    "    \"Portuguese\": \"por_Latn\",\n",
    "    \"Italian\": \"ita_Latn\",\n",
    "}\n",
    "TARGET_LANGUAGES = [\"Spanish\", \"English\", \"Portuguese\", \"Italian\"]\n",
    "\n",
    "CATALAN_FILLERS = [\n",
    "    r\"per dir-ho d'alguna manera\", r\"diguem-ne\", r\"a veure\", r\"o sigui\",\n",
    "    r\"vull dir\", r\"\\u00e9s a dir\", r\"llavors\", r\"bueno\", r\"doncs\",\n",
    "    r\"saps\\?\", r\"vale\", r\"clar\", r\"oi\\?\", r\"no\\?\", r\"b\\u00e9\",\n",
    "    r\"ehm+\", r\"eh+\", r\"mm+\", r\"um+\", r\"ah+\",\n",
    "]\n",
    "\n",
    "CLEANUP_PROMPT = \"\"\"You are a text editor. The following is a transcription of a university \\\n",
    "lecture in Catalan. Clean it up by:\n",
    "1. Organizing into logical paragraphs\n",
    "2. Fixing any obvious transcription errors\n",
    "3. Removing remaining verbal fillers or repetitions\n",
    "4. Do NOT change the language or the meaning\n",
    "5. Do NOT add any commentary or explanations\n",
    "6. Return ONLY the cleaned text\n",
    "\n",
    "Transcription:\n",
    "{text}\"\"\"\n",
    "\n",
    "SUMMARY_PROMPT = \"\"\"You are an academic assistant. Summarize the following university lecture \\\n",
    "transcript. The lecture is in {language}. Provide your summary in {language}.\n",
    "\n",
    "Format your response as:\n",
    "## Main Topics\n",
    "- [bullet points of 5-10 key topics covered]\n",
    "\n",
    "## Detailed Summary\n",
    "[2-3 paragraphs summarizing the lecture content]\n",
    "\n",
    "## Key Terms\n",
    "- [list of important technical terms or concepts mentioned]\n",
    "\n",
    "Transcript:\n",
    "{text}\"\"\"\n",
    "\n",
    "CHUNK_SUMMARY_PROMPT = \"\"\"You are an academic assistant. Summarize this section of a university \\\n",
    "lecture transcript. The lecture is in {language}. Provide a concise summary in {language} \\\n",
    "capturing the key points, concepts, and any important terminology.\n",
    "\n",
    "Section:\n",
    "{text}\"\"\"\n",
    "\n",
    "SUPPORTED_AUDIO_FORMATS = [\".m4a\", \".mp3\", \".wav\", \".ogg\", \".webm\", \".flac\"]\n",
    "NLLB_MAX_LENGTH = 512\n",
    "NLLB_BATCH_MAX_TOKENS = 400\n",
    "LLM_CHUNK_MAX_WORDS = 3000\n",
    "SLIDE_MAX_BULLETS = 6\n",
    "\n",
    "print(\"Configuration loaded!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 5: Transcriber (GPU path using transformers pipeline)\n",
    "\n",
    "class Transcriber:\n",
    "    def __init__(self):\n",
    "        self._pipe = None\n",
    "\n",
    "    def _load_model(self):\n",
    "        import torch\n",
    "        from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "        logger.info(\"Loading Whisper model: %s\", WHISPER_HF_MODEL)\n",
    "        processor = AutoProcessor.from_pretrained(WHISPER_HF_MODEL)\n",
    "        model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "            WHISPER_HF_MODEL, torch_dtype=torch.float16, low_cpu_mem_usage=True\n",
    "        ).to(\"cuda:0\")\n",
    "\n",
    "        self._pipe = pipeline(\n",
    "            \"automatic-speech-recognition\",\n",
    "            model=model,\n",
    "            tokenizer=processor.tokenizer,\n",
    "            feature_extractor=processor.feature_extractor,\n",
    "            torch_dtype=torch.float16,\n",
    "            device=\"cuda:0\",\n",
    "            chunk_length_s=30,\n",
    "            batch_size=16,\n",
    "            return_timestamps=True,\n",
    "        )\n",
    "        logger.info(\"Whisper model loaded on GPU\")\n",
    "\n",
    "    def transcribe(self, audio_path, progress_callback=None):\n",
    "        if self._pipe is None:\n",
    "            if progress_callback:\n",
    "                progress_callback(0.05, desc=\"Loading Whisper model...\")\n",
    "            self._load_model()\n",
    "\n",
    "        if progress_callback:\n",
    "            progress_callback(0.10, desc=\"Transcribing audio...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "        output = self._pipe(\n",
    "            audio_path,\n",
    "            generate_kwargs={\"language\": \"ca\", \"task\": \"transcribe\"},\n",
    "        )\n",
    "\n",
    "        segments = []\n",
    "        if \"chunks\" in output:\n",
    "            for chunk in output[\"chunks\"]:\n",
    "                ts = chunk.get(\"timestamp\", (None, None))\n",
    "                segments.append({\n",
    "                    \"start\": ts[0] if ts[0] is not None else 0.0,\n",
    "                    \"end\": ts[1] if ts[1] is not None else 0.0,\n",
    "                    \"text\": chunk[\"text\"].strip(),\n",
    "                })\n",
    "\n",
    "        if progress_callback:\n",
    "            progress_callback(0.50, desc=\"Transcription complete\")\n",
    "\n",
    "        return {\n",
    "            \"text\": output[\"text\"].strip(),\n",
    "            \"segments\": segments,\n",
    "            \"language\": \"ca\",\n",
    "            \"duration_seconds\": time.time() - t0,\n",
    "        }\n",
    "\n",
    "print(\"Transcriber ready\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 6: Text Cleaner (regex + optional LLM)\n\ndef _build_filler_pattern(fillers):\n    sorted_fillers = sorted(fillers, key=len, reverse=True)\n    pattern = r\"\\b(?:\" + \"|\".join(sorted_fillers) + r\")\\b\"\n    return re.compile(pattern, re.IGNORECASE | re.UNICODE)\n\nclass TextCleaner:\n    def __init__(self):\n        self._filler_pattern = _build_filler_pattern(CATALAN_FILLERS)\n\n    def _has_gemini(self):\n        return bool(os.environ.get(\"GEMINI_API_KEY\"))\n\n    def _call_gemini(self, prompt):\n        from google import genai\n        client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n        response = client.models.generate_content(\n            model=\"gemini-2.0-flash\", contents=prompt\n        )\n        return response.text.strip()\n\n    def regex_clean(self, text):\n        if not text:\n            return \"\"\n        cleaned = self._filler_pattern.sub(\"\", text)\n        cleaned = re.sub(r\"[ \\t]+\", \" \", cleaned)\n        cleaned = re.sub(r\" ([.,;:!?])\", r\"\\1\", cleaned)\n        cleaned = re.sub(r\"\\n{3,}\", \"\\n\\n\", cleaned)\n        cleaned = cleaned.strip()\n        # Fix capitalization\n        cleaned = re.sub(\n            r\"([.!?]\\s+)([a-z\\u00e1\\u00e0\\u00e9\\u00e8\\u00ed\\u00ef\\u00f3\\u00f2\\u00fa\\u00fc\\u00e7])\",\n            lambda m: m.group(1) + m.group(2).upper(), cleaned\n        )\n        if cleaned and cleaned[0].islower():\n            cleaned = cleaned[0].upper() + cleaned[1:]\n        return cleaned\n\n    def clean(self, text, progress_callback=None):\n        if progress_callback:\n            progress_callback(0.50, desc=\"Removing filler words...\")\n        regex_cleaned = self.regex_clean(text)\n\n        llm_cleaned = None\n        if self._has_gemini():\n            if progress_callback:\n                progress_callback(0.52, desc=\"Restructuring text with Gemini...\")\n            try:\n                chunks = _chunk_text(regex_cleaned)\n                parts = []\n                for i, chunk in enumerate(chunks):\n                    if progress_callback:\n                        frac = 0.52 + 0.08 * ((i + 1) / len(chunks))\n                        progress_callback(frac, desc=f\"Restructuring chunk {i+1}/{len(chunks)}...\")\n                    prompt = CLEANUP_PROMPT.format(text=chunk)\n                    parts.append(self._call_gemini(prompt))\n                llm_cleaned = \"\\n\\n\".join(parts)\n            except Exception as e:\n                logger.warning(\"Gemini cleanup failed: %s\", e)\n\n        return {\n            \"regex_cleaned\": regex_cleaned,\n            \"llm_cleaned\": llm_cleaned,\n            \"best\": llm_cleaned if llm_cleaned else regex_cleaned,\n        }\n\ndef _chunk_text(text, max_words=LLM_CHUNK_MAX_WORDS):\n    sentences = re.split(r\"(?<=[.!?])\\s+\", text)\n    chunks, current_chunk, current_count = [], [], 0\n    for sentence in sentences:\n        word_count = len(sentence.split())\n        if current_count + word_count > max_words and current_chunk:\n            chunks.append(\" \".join(current_chunk))\n            current_chunk, current_count = [], 0\n        current_chunk.append(sentence)\n        current_count += word_count\n    if current_chunk:\n        chunks.append(\" \".join(current_chunk))\n    return chunks\n\nprint(\"TextCleaner ready\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 7: Translator (NLLB-200)\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self):\n",
    "        self._model = None\n",
    "        self._tokenizer = None\n",
    "\n",
    "    def _load_model(self):\n",
    "        from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "        import torch\n",
    "\n",
    "        logger.info(\"Loading NLLB-200 translation model...\")\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(NLLB_MODEL)\n",
    "        self._model = AutoModelForSeq2SeqLM.from_pretrained(NLLB_MODEL)\n",
    "        if torch.cuda.is_available():\n",
    "            self._model = self._model.half().to(\"cuda\")\n",
    "        logger.info(\"Translation model loaded\")\n",
    "\n",
    "    def _ensure_loaded(self):\n",
    "        if self._model is None:\n",
    "            self._load_model()\n",
    "\n",
    "    def _split_into_batches(self, text):\n",
    "        sentences = re.split(r\"(?<=[.!?;:])\\s+\", text)\n",
    "        batches, current_batch, current_tokens = [], [], 0\n",
    "        for sentence in sentences:\n",
    "            tokens = len(self._tokenizer.encode(sentence, add_special_tokens=False))\n",
    "            if current_tokens + tokens > NLLB_BATCH_MAX_TOKENS and current_batch:\n",
    "                batches.append(\" \".join(current_batch))\n",
    "                current_batch, current_tokens = [], 0\n",
    "            current_batch.append(sentence)\n",
    "            current_tokens += tokens\n",
    "        if current_batch:\n",
    "            batches.append(\" \".join(current_batch))\n",
    "        return batches\n",
    "\n",
    "    def translate_text(self, text, source_lang, target_lang):\n",
    "        if not text or not text.strip():\n",
    "            return \"\"\n",
    "        self._ensure_loaded()\n",
    "\n",
    "        src_code = LANGUAGE_CODES[source_lang]\n",
    "        tgt_code = LANGUAGE_CODES[target_lang]\n",
    "        tgt_token_id = self._tokenizer.convert_tokens_to_ids(tgt_code)\n",
    "\n",
    "        self._tokenizer.src_lang = src_code\n",
    "        batches = self._split_into_batches(text)\n",
    "        translated_parts = []\n",
    "\n",
    "        device = \"cuda\" if next(self._model.parameters()).is_cuda else \"cpu\"\n",
    "        for batch in batches:\n",
    "            inputs = self._tokenizer(\n",
    "                batch, return_tensors=\"pt\", padding=True,\n",
    "                truncation=True, max_length=NLLB_MAX_LENGTH\n",
    "            )\n",
    "            if device == \"cuda\":\n",
    "                inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "            outputs = self._model.generate(\n",
    "                **inputs, forced_bos_token_id=tgt_token_id, max_length=NLLB_MAX_LENGTH\n",
    "            )\n",
    "            decoded = self._tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            translated_parts.extend(decoded)\n",
    "\n",
    "        return \" \".join(translated_parts)\n",
    "\n",
    "    def translate_to_languages(self, text, target_languages, progress_callback=None):\n",
    "        translations = {}\n",
    "        for i, lang in enumerate(target_languages):\n",
    "            if progress_callback:\n",
    "                frac = 0.60 + 0.20 * (i / len(target_languages))\n",
    "                progress_callback(frac, desc=f\"Translating to {lang}...\")\n",
    "            try:\n",
    "                translations[lang] = self.translate_text(text, \"Catalan\", lang)\n",
    "            except Exception as e:\n",
    "                logger.error(\"Translation to %s failed: %s\", lang, e)\n",
    "                translations[lang] = f\"[Translation to {lang} failed: {e}]\"\n",
    "        if progress_callback:\n",
    "            progress_callback(0.80, desc=\"Translation complete\")\n",
    "        return translations\n",
    "\n",
    "print(\"Translator ready\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 8: Summarizer\n\nclass Summarizer:\n    def __init__(self):\n        pass\n\n    def _has_gemini(self):\n        return bool(os.environ.get(\"GEMINI_API_KEY\"))\n\n    def _call_gemini(self, prompt):\n        from google import genai\n        client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n        response = client.models.generate_content(\n            model=\"gemini-2.0-flash\", contents=prompt\n        )\n        return response.text.strip()\n\n    def summarize(self, text, language=\"Catalan\", progress_callback=None):\n        if progress_callback:\n            progress_callback(0.80, desc=\"Generating summary...\")\n\n        if not self._has_gemini():\n            logger.info(\"No Gemini key, skipping summarization\")\n            return {\"raw_summary\": None, \"main_topics\": [], \"detailed_summary\": \"\",\n                    \"key_terms\": [], \"sections\": []}\n\n        word_count = len(text.split())\n        try:\n            if word_count > LLM_CHUNK_MAX_WORDS:\n                raw = self._map_reduce(text, language, progress_callback)\n            else:\n                raw = self._call_gemini(SUMMARY_PROMPT.format(language=language, text=text))\n        except Exception as e:\n            logger.warning(\"Summarization failed: %s\", e)\n            return {\"raw_summary\": None, \"main_topics\": [], \"detailed_summary\": \"\",\n                    \"key_terms\": [], \"sections\": []}\n\n        if progress_callback:\n            progress_callback(0.90, desc=\"Summary complete\")\n\n        return {\n            \"raw_summary\": raw,\n            \"main_topics\": self._extract_list(raw, \"Main Topics\"),\n            \"detailed_summary\": self._extract_section(raw, \"Detailed Summary\"),\n            \"key_terms\": self._extract_list(raw, \"Key Terms\"),\n            \"sections\": self._parse_sections(raw),\n        }\n\n    def _map_reduce(self, text, language, progress_callback=None):\n        chunks = _chunk_text(text)\n        summaries = []\n        for i, chunk in enumerate(chunks):\n            if progress_callback:\n                frac = 0.82 + 0.06 * ((i + 1) / len(chunks))\n                progress_callback(frac, desc=f\"Summarizing section {i+1}/{len(chunks)}...\")\n            prompt = CHUNK_SUMMARY_PROMPT.format(language=language, text=chunk)\n            summaries.append(self._call_gemini(prompt))\n        combined = \"\\n\\n\".join(summaries)\n        if progress_callback:\n            progress_callback(0.88, desc=\"Generating final summary...\")\n        return self._call_gemini(SUMMARY_PROMPT.format(language=language, text=combined))\n\n    def _parse_sections(self, text):\n        sections, title, bullets = [], None, []\n        for line in text.split(\"\\n\"):\n            line = line.strip()\n            if line.startswith(\"## \"):\n                if title:\n                    sections.append({\"title\": title, \"bullets\": bullets})\n                title, bullets = line[3:].strip(), []\n            elif (line.startswith(\"- \") or line.startswith(\"* \")) and title:\n                bullets.append(line[2:].strip())\n            elif line and title:\n                bullets.append(line)\n        if title:\n            sections.append({\"title\": title, \"bullets\": bullets})\n        return sections\n\n    def _extract_list(self, text, header):\n        in_section, items = False, []\n        for line in text.split(\"\\n\"):\n            s = line.strip()\n            if s.startswith(\"## \") and header.lower() in s.lower():\n                in_section = True\n            elif s.startswith(\"## \") and in_section:\n                break\n            elif in_section and (s.startswith(\"- \") or s.startswith(\"* \")):\n                items.append(s[2:].strip())\n        return items\n\n    def _extract_section(self, text, header):\n        in_section, parts = False, []\n        for line in text.split(\"\\n\"):\n            s = line.strip()\n            if s.startswith(\"## \") and header.lower() in s.lower():\n                in_section = True\n            elif s.startswith(\"## \") and in_section:\n                break\n            elif in_section and s:\n                parts.append(s)\n        return \"\\n\\n\".join(parts)\n\nprint(\"Summarizer ready\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 9: Slide Generator\n",
    "\n",
    "from pptx import Presentation as PptxPresentation\n",
    "from pptx.util import Inches, Pt\n",
    "from pptx.dml.color import RGBColor\n",
    "from pptx.enum.text import PP_ALIGN\n",
    "\n",
    "COLOR_TITLE = RGBColor(0x1A, 0x47, 0x8A)\n",
    "COLOR_BODY = RGBColor(0x33, 0x33, 0x33)\n",
    "COLOR_LIGHT = RGBColor(0x85, 0x92, 0x9E)\n",
    "\n",
    "class SlideGenerator:\n",
    "    def generate(self, summary_data, title=\"Lecture Summary\", output_path=None):\n",
    "        prs = PptxPresentation()\n",
    "        prs.slide_width = Inches(13.333)\n",
    "        prs.slide_height = Inches(7.5)\n",
    "\n",
    "        # Title slide\n",
    "        slide = prs.slides.add_slide(prs.slide_layouts[0])\n",
    "        slide.shapes.title.text = title\n",
    "        for p in slide.shapes.title.text_frame.paragraphs:\n",
    "            p.font.size, p.font.color.rgb, p.font.bold = Pt(36), COLOR_TITLE, True\n",
    "        if len(slide.placeholders) > 1:\n",
    "            slide.placeholders[1].text = f\"Generated {date.today().isoformat()}\"\n",
    "\n",
    "        # Overview\n",
    "        topics = summary_data.get(\"main_topics\", [])\n",
    "        if topics:\n",
    "            self._add_content_slide(prs, \"Overview\", topics)\n",
    "\n",
    "        # Sections\n",
    "        for sec in summary_data.get(\"sections\", []):\n",
    "            if sec.get(\"title\") and sec.get(\"bullets\"):\n",
    "                self._add_content_slide(prs, sec[\"title\"], sec[\"bullets\"])\n",
    "\n",
    "        # Key terms\n",
    "        terms = summary_data.get(\"key_terms\", [])\n",
    "        if terms:\n",
    "            self._add_content_slide(prs, \"Key Terms & Concepts\", terms)\n",
    "\n",
    "        # End slide\n",
    "        slide = prs.slides.add_slide(prs.slide_layouts[0])\n",
    "        slide.shapes.title.text = \"End of Summary\"\n",
    "        for p in slide.shapes.title.text_frame.paragraphs:\n",
    "            p.font.size, p.font.color.rgb = Pt(36), COLOR_TITLE\n",
    "            p.alignment = PP_ALIGN.CENTER\n",
    "\n",
    "        if output_path is None:\n",
    "            output_path = f\"/tmp/lecture_slides_{date.today().isoformat()}.pptx\"\n",
    "        prs.save(output_path)\n",
    "        return output_path\n",
    "\n",
    "    def _add_content_slide(self, prs, title_text, bullets):\n",
    "        for idx in range(0, len(bullets), SLIDE_MAX_BULLETS):\n",
    "            page = bullets[idx:idx + SLIDE_MAX_BULLETS]\n",
    "            st = f\"{title_text} (cont.)\" if idx > 0 else title_text\n",
    "            slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "            slide.shapes.title.text = st\n",
    "            for p in slide.shapes.title.text_frame.paragraphs:\n",
    "                p.font.size, p.font.color.rgb, p.font.bold = Pt(28), COLOR_TITLE, True\n",
    "            if len(slide.placeholders) > 1:\n",
    "                tf = slide.placeholders[1].text_frame\n",
    "                tf.clear()\n",
    "                for i, b in enumerate(page):\n",
    "                    p = tf.paragraphs[0] if i == 0 else tf.add_paragraph()\n",
    "                    p.text = b\n",
    "                    p.font.size, p.font.color.rgb = Pt(18), COLOR_BODY\n",
    "                    p.space_after = Pt(8)\n",
    "\n",
    "print(\"SlideGenerator ready\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 10: Pipeline Orchestrator\n\nimport shutil\nimport zipfile\n\nTOTAL_STEPS = 5\n\ndef _progress_bar(fraction, width=30):\n    \"\"\"Render a text-based progress bar like [████████░░░░░░░░░░░░] 40%\"\"\"\n    fraction = max(0.0, min(1.0, fraction))\n    filled = int(width * fraction)\n    bar = \"\\u2588\" * filled + \"\\u2591\" * (width - filled)\n    return f\"[{bar}] {fraction * 100:.0f}%\"\n\ndef _step(n, title, detail=\"\", progress=None):\n    \"\"\"Format a step status string with optional progress bar.\"\"\"\n    header = f\"Step {n}/{TOTAL_STEPS} \\u2014 {title}\"\n    if progress is not None:\n        header += f\"  {_progress_bar(progress)}\"\n    if detail:\n        return f\"{header}\\n{detail}\"\n    return header\n\nclass LectureProcessor:\n    def __init__(self):\n        self._transcriber = Transcriber()\n        self._cleaner = TextCleaner()\n        self._translator = Translator()\n        self._summarizer = Summarizer()\n        self._slides = SlideGenerator()\n\n    def process(self, audio_path, target_languages):\n        \"\"\"Generator that yields (status_message, results_dict) tuples.\"\"\"\n        results = {\n            \"transcript_raw\": None, \"transcript_clean\": None,\n            \"translations\": {}, \"summary\": None,\n            \"summaries\": {}, \"summaries_data\": {},\n            \"all_files\": {}, \"errors\": [], \"timings\": {},\n        }\n        output_dir = tempfile.mkdtemp(prefix=\"lecture_\")\n\n        # Copy audio so Gradio and transcriber don't lock the same file\n        audio_copy = os.path.join(output_dir, os.path.basename(audio_path))\n        shutil.copy2(audio_path, audio_copy)\n        audio_path = audio_copy\n\n        # Validate\n        ext = os.path.splitext(audio_path)[1].lower()\n        if ext not in SUPPORTED_AUDIO_FORMATS:\n            results[\"errors\"].append(f\"Unsupported format: {ext}\")\n            yield (f\"Error: Unsupported format {ext}\", results)\n            return\n\n        # Step 1: Transcribe\n        yield (_step(1, \"Transcribing\", \"Loading model... (this takes up to 30s)\"), results)\n        t0 = time.time()\n        try:\n            tr = self._transcriber.transcribe(audio_path)\n            results[\"transcript_raw\"] = tr[\"text\"]\n            results[\"timings\"][\"transcription\"] = time.time() - t0\n            path = os.path.join(output_dir, \"transcript_raw.txt\")\n            open(path, \"w\", encoding=\"utf-8\").write(results[\"transcript_raw\"])\n            results[\"all_files\"][\"transcript_raw.txt\"] = path\n        except Exception as e:\n            results[\"errors\"].append(f\"Transcription failed: {e}\")\n            yield (f\"Transcription failed: {e}\", results)\n            return\n\n        # Step 2: Clean text\n        yield (_step(2, \"Cleaning text\", \"Removing filler words...\"), results)\n        t0 = time.time()\n        try:\n            cr = self._cleaner.clean(results[\"transcript_raw\"])\n            results[\"transcript_clean\"] = cr[\"best\"]\n            results[\"timings\"][\"cleanup\"] = time.time() - t0\n            path = os.path.join(output_dir, \"transcript_clean.txt\")\n            open(path, \"w\", encoding=\"utf-8\").write(results[\"transcript_clean\"])\n            results[\"all_files\"][\"transcript_clean.txt\"] = path\n        except Exception as e:\n            results[\"errors\"].append(f\"Cleanup failed: {e}\")\n            results[\"transcript_clean\"] = results[\"transcript_raw\"]\n\n        # Step 3: Translate\n        yield (_step(3, \"Translating\", \"Loading model... (this takes up to 30s)\"), results)\n        t0 = time.time()\n        text_to_translate = results[\"transcript_clean\"] or results[\"transcript_raw\"]\n        try:\n            self._translator._ensure_loaded()\n            num_langs = len(target_languages)\n            for i, lang in enumerate(target_languages):\n                frac = i / num_langs\n                yield (_step(3, \"Translating\", f\"{lang}...\", progress=frac), results)\n                try:\n                    results[\"translations\"][lang] = self._translator.translate_text(\n                        text_to_translate, \"Catalan\", lang\n                    )\n                    txt = results[\"translations\"][lang]\n                    if not txt.startswith(\"[Translation\"):\n                        fn = f\"translation_{lang.lower()}.txt\"\n                        path = os.path.join(output_dir, fn)\n                        open(path, \"w\", encoding=\"utf-8\").write(txt)\n                        results[\"all_files\"][fn] = path\n                except Exception as e:\n                    logger.error(\"Translation to %s failed: %s\", lang, e)\n                    results[\"translations\"][lang] = f\"[Translation to {lang} failed: {e}]\"\n            results[\"timings\"][\"translation\"] = time.time() - t0\n        except Exception as e:\n            results[\"errors\"].append(f\"Translation failed: {e}\")\n\n        # Step 4: Summarize (per translated language)\n        t0 = time.time()\n        num_summary_langs = len(target_languages)\n        for lang_idx, lang in enumerate(target_languages):\n            translated_text = results[\"translations\"].get(lang, \"\")\n            if not translated_text or translated_text.startswith(\"[Translation\"):\n                continue\n            frac = lang_idx / num_summary_langs\n            yield (_step(4, \"Summarizing\", f\"{lang}...\", progress=frac), results)\n            try:\n                sd = self._summarizer.summarize(translated_text, lang)\n                raw = sd.get(\"raw_summary\")\n                results[\"summaries\"][lang] = raw\n                results[\"summaries_data\"][lang] = sd\n                if raw:\n                    fn = f\"summary_{lang.lower()}.md\"\n                    path = os.path.join(output_dir, fn)\n                    open(path, \"w\", encoding=\"utf-8\").write(raw)\n                    results[\"all_files\"][fn] = path\n            except Exception as e:\n                logger.error(\"Summarization for %s failed: %s\", lang, e)\n                results[\"errors\"].append(f\"Summarization ({lang}) failed: {e}\")\n        results[\"timings\"][\"summarization\"] = time.time() - t0\n\n        # Build combined summary for UI display\n        summary_parts = []\n        for lang in target_languages:\n            raw = results[\"summaries\"].get(lang)\n            if raw:\n                summary_parts.append(f\"## {lang}\\n\\n{raw}\")\n        results[\"summary\"] = \"\\n\\n---\\n\\n\".join(summary_parts) if summary_parts else None\n\n        # Step 5: Generate slides (per language)\n        yield (_step(5, \"Creating slides\"), results)\n        t0 = time.time()\n        slides_created = 0\n        audio_name = os.path.splitext(os.path.basename(audio_path))[0]\n        for lang in target_languages:\n            sd = results.get(\"summaries_data\", {}).get(lang, {})\n            if not (sd.get(\"main_topics\") or sd.get(\"sections\")):\n                continue\n            try:\n                slides_path = os.path.join(output_dir, f\"lecture_slides_{lang.lower()}.pptx\")\n                self._slides.generate(sd, title=f\"{audio_name} ({lang})\", output_path=slides_path)\n                results[\"all_files\"][f\"lecture_slides_{lang.lower()}.pptx\"] = slides_path\n                slides_created += 1\n            except Exception as e:\n                logger.error(\"Slide generation for %s failed: %s\", lang, e)\n                results[\"errors\"].append(f\"Slides ({lang}) failed: {e}\")\n        if slides_created == 0:\n            results[\"errors\"].append(\"Slides skipped: no summary data available\")\n        results[\"timings\"][\"slides\"] = time.time() - t0\n\n        # Create ZIP of all output files\n        if results[\"all_files\"]:\n            try:\n                zip_path = os.path.join(output_dir, \"lecture_all_files.zip\")\n                with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n                    for filename, filepath in results[\"all_files\"].items():\n                        zf.write(filepath, filename)\n                results[\"zip_path\"] = zip_path\n            except Exception as e:\n                logger.error(\"ZIP creation failed: %s\", e)\n\n        timing_parts = [f\"{k}: {v:.1f}s\" for k, v in results[\"timings\"].items()]\n        status = \"Done! \" + \" | \".join(timing_parts) if timing_parts else \"Done!\"\n        yield (status, results)\n\nprint(\"LectureProcessor ready\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 11: Gradio UI and Launch\n\nimport gradio as gr\n\nprocessor = LectureProcessor()\n\nwith gr.Blocks(title=\"Catalan Lecture Processor\") as app:\n\n    gr.Markdown(\n        \"# Catalan Lecture Processor\\n\"\n        \"Upload a lecture recording in Catalan. Get transcription, \"\n        \"translation, summary, and PowerPoint slides.\"\n    )\n\n    with gr.Group():\n        gr.Markdown(\"### Upload Audio\")\n        audio_input = gr.Audio(\n            label=\"Lecture audio (m4a, mp3, wav, ogg, webm, flac)\",\n            type=\"filepath\", sources=[\"upload\"],\n        )\n        target_langs = gr.CheckboxGroup(\n            choices=TARGET_LANGUAGES, value=[\"Spanish\", \"English\"],\n            label=\"Translate to:\",\n        )\n        process_btn = gr.Button(\"Process Lecture\", variant=\"primary\", size=\"lg\")\n\n    # Status above tabs for visibility\n    status_text = gr.Textbox(label=\"Status\", interactive=False, lines=3)\n    errors_text = gr.Textbox(label=\"Warnings\", interactive=False, lines=2, visible=False)\n\n    with gr.Tabs():\n        with gr.Tab(\"Transcript\"):\n            transcript_raw = gr.Textbox(label=\"Raw Transcription (Catalan)\", lines=12, max_lines=30)\n            transcript_clean = gr.Textbox(label=\"Cleaned Transcription\", lines=12, max_lines=30)\n\n        with gr.Tab(\"Translations\"):\n            trans_boxes = {}\n            for lang in TARGET_LANGUAGES:\n                trans_boxes[lang] = gr.Textbox(\n                    label=f\"{lang} Translation\", lines=10,\n                    visible=(lang in [\"Spanish\", \"English\"]),\n                )\n\n        with gr.Tab(\"Summary\"):\n            summary_output = gr.Markdown(label=\"Lecture Summary\")\n\n        with gr.Tab(\"Downloads\"):\n            download_zip = gr.File(\n                label=\"Download All (ZIP)\",\n                file_count=\"single\",\n            )\n            gr.Markdown(\"Or download individual files:\")\n            download_files = gr.File(label=\"Individual Files\", file_count=\"multiple\")\n\n    def update_visibility(languages):\n        return [gr.update(visible=(l in languages)) for l in TARGET_LANGUAGES]\n\n    target_langs.change(\n        update_visibility, inputs=[target_langs],\n        outputs=list(trans_boxes.values()),\n    )\n\n    def process_lecture(audio, languages):\n        \"\"\"Generator that yields UI updates from the pipeline.\"\"\"\n        if audio is None:\n            raise gr.Error(\"Please upload an audio file first.\")\n        if not languages:\n            raise gr.Error(\"Please select at least one target language.\")\n\n        def build_output(status, results):\n            raw = results.get(\"transcript_raw\") or \"\"\n            clean = results.get(\"transcript_clean\") or \"\"\n            translations = results.get(\"translations\", {})\n            trans_outputs = [translations.get(l, \"\") for l in TARGET_LANGUAGES]\n            summary = results.get(\"summary\") or \"\"\n            zip_path = results.get(\"zip_path\")\n            files_list = list(results.get(\"all_files\", {}).values()) or None\n            errors = results.get(\"errors\", [])\n            errors_str = \"\\n\".join(errors) if errors else \"\"\n            return (\n                status,\n                gr.update(value=errors_str, visible=bool(errors)),\n                raw, clean,\n                *trans_outputs,\n                summary, zip_path, files_list,\n            )\n\n        for status, results in processor.process(audio, languages):\n            yield build_output(status, results)\n\n    all_outputs = [\n        status_text, errors_text,\n        transcript_raw, transcript_clean,\n        *list(trans_boxes.values()),\n        summary_output, download_zip, download_files,\n    ]\n\n    process_btn.click(\n        process_lecture,\n        inputs=[audio_input, target_langs],\n        outputs=all_outputs,\n    )\n\n# Launch with public link for phone access\napp.launch(\n    share=True,\n    debug=True,\n    theme=gr.themes.Soft(),\n    css=\".gradio-container { max-width: 960px !important; margin: auto; }\",\n)",
   "execution_count": null,
   "outputs": []
  }
 ]
}